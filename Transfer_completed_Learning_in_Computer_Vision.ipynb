{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muyiiwaa/machine_learning_notes/blob/master/Transfer_completed_Learning_in_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0OYToLoFAu2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import timm\n",
        "import wandb\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "data_path = os.listdir(path)\n",
        "data_path = os.path.join(path, data_path[1])\n",
        "data_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Z-_GiX8FGD5h",
        "outputId": "04bd87c5-5a90-4aa4-cea6-c03f1a385e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/animals10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/animals10/raw-img'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load and prepare the dataset\n",
        "\n",
        "# setup the transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.RandomHorizontalFlip(p=0.4),\n",
        "    transforms.ColorJitter(brightness=0.2, saturation=0.2,\n",
        "                           hue=0.1,contrast=0.1),\n",
        "    transforms.Resize((200,200))\n",
        "])\n",
        "\n",
        "# load the images\n",
        "data = datasets.ImageFolder(root=data_path,transform=transform)\n",
        "\n",
        "\n",
        "# split the data into train and test set\n",
        "train_size = int(0.6 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_data, test_data = random_split(dataset=data, lengths=[train_size, test_size])\n",
        "\n",
        "# repeat this step to split test (40% of the data) into train and test set to fit gpu.\n",
        "train_size = int(0.8 * len(test_data))\n",
        "test_size = len(test_data) - train_size\n",
        "train_data, test_data = random_split(dataset=test_data, lengths=[train_size, test_size])\n",
        "\n",
        "\n",
        "# setup the data loader\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(dataset = train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "3mSoGcOWGNPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the model architecture and hyperparameters\n",
        "\n",
        "model = timm.create_model(model_name='efficientnet_b3', pretrained=True)\n",
        "model.classifier = nn.Linear(in_features=model.classifier.in_features, out_features=10)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "LEARNING_RATE = 1e-4\n",
        "optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=2, gamma=0.1)\n",
        "EPOCHS = 10\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "K_tjFS1aJguz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal_list = ['dog','horse','elephant',\n",
        "               'butterfly','chicken','cat',\n",
        "               'cow','sheep','spider','squirrel']\n",
        "len(animal_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU7VXasDJuKK",
        "outputId": "2342b9f4-5834-478b-c3ce-62b7bf8c650d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init wandb for tracking\n",
        "\n",
        "run = wandb.init(\n",
        "    project = 'Animal Classification With Fine Tuned EfficientNet-B3',\n",
        "    name= 'second run',\n",
        "    config= {\n",
        "        'model_name': 'efficientnet-b3',\n",
        "        'device': device,\n",
        "        'data_path': data_path,\n",
        "        'learning rate': LEARNING_RATE,\n",
        "        'optimizer': 'AdamW',\n",
        "        'weight decay': 0.01,\n",
        "        'scheduler': {'step': 2, 'gamma': 0.1},\n",
        "        'epochs': EPOCHS\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "s9Tm1Aa1MoAj",
        "outputId": "27973508-4e5c-4010-82c1-eed7836dca64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">second run</strong> at: <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/4fuf9zny' target=\"_blank\">https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/4fuf9zny</a><br> View project at: <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3' target=\"_blank\">https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250626_134536-4fuf9zny/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250626_134644-goq7yrfs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/goq7yrfs' target=\"_blank\">second run</a></strong> to <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3' target=\"_blank\">https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/goq7yrfs' target=\"_blank\">https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/goq7yrfs</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# begin the training loop\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_epoch_loss, test_epoch_loss = [], []\n",
        "  train_epoch_labels, train_epoch_preds = [], []\n",
        "  test_epoch_labels, test_epoch_preds = [], []\n",
        "  train_batch = tqdm(train_loader, desc= f'Training Epoch: {epoch+1}/{EPOCHS}')\n",
        "  for image, label in train_batch:\n",
        "    model.train()\n",
        "    image, label = image.to(device), label.to(device)\n",
        "    train_preds = model(image)\n",
        "    loss = criterion(train_preds, label)\n",
        "\n",
        "    # back propagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_epoch_loss.append(loss.item())\n",
        "    train_epoch_labels.extend(label.cpu().detach().numpy())\n",
        "    _, train_preds = torch.max(train_preds, 1)\n",
        "    train_epoch_preds.extend(train_preds.cpu().detach().numpy())\n",
        "\n",
        "    train_batch.set_postfix(loss=loss.item())\n",
        "\n",
        "  scheduler.step()\n",
        "  # compute the f1_score, precision and recall for training set\n",
        "  train_final_loss = sum(train_epoch_loss)/len(train_epoch_loss)\n",
        "  train_f1 = f1_score(train_epoch_labels, train_epoch_preds, average='weighted')\n",
        "  train_precision = precision_score(train_epoch_labels, train_epoch_preds, average='weighted')\n",
        "  train_recall = recall_score(train_epoch_labels, train_epoch_preds, average='weighted')\n",
        "\n",
        "  # now evaluate\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    test_batch = tqdm(test_loader, desc= f'Evaluating tests for Epoch: {epoch+1}/{EPOCHS}')\n",
        "    for test_image, test_labels in test_batch:\n",
        "      test_image, test_labels = test_image.to(device), test_labels.to(device)\n",
        "      test_preds = model(test_image)\n",
        "\n",
        "\n",
        "      test_loss = criterion(test_preds, test_labels)\n",
        "      test_epoch_loss.append(test_loss.item())\n",
        "      test_epoch_labels.extend(test_labels.cpu().detach().numpy())\n",
        "      _, test_preds = torch.max(test_preds, 1)\n",
        "      test_epoch_preds.extend(test_preds.cpu().detach().numpy())\n",
        "\n",
        "  # compute the f1_score, precision and recall for test set\n",
        "  test_final_loss = sum(test_epoch_loss)/len(test_epoch_loss)\n",
        "  test_f1 = f1_score(test_epoch_labels, test_epoch_preds, average='weighted')\n",
        "  test_precision = precision_score(test_epoch_labels, test_epoch_preds, average='weighted')\n",
        "  test_recall = recall_score(test_epoch_labels, test_epoch_preds, average='weighted')\n",
        "\n",
        "  print(f'Completed training Epoch: {epoch+1}..f1: {train_f1, test_f1}, loss: {train_final_loss, test_final_loss}')\n",
        "  print(f'Completed training Epoch: {epoch+1}..recall: {train_recall, test_recall}, precision: {train_precision, test_precision}')\n",
        "\n",
        "  # append result in wandb\n",
        "  run.log({\n",
        "      'epochs': epoch + 1,\n",
        "      'train loss': train_final_loss,\n",
        "      'test loss': test_final_loss,\n",
        "      'train f1': train_f1,\n",
        "      'train precision': train_precision,\n",
        "      'train recall': train_recall,\n",
        "      'test f1': test_f1,\n",
        "      'test precision': test_precision,\n",
        "      'test recall': test_recall\n",
        "  })\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1d0LyjqQN3nQ",
        "outputId": "eda615ea-4974-4127-f409-15975e94bb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 1/10: 100%|██████████| 262/262 [06:11<00:00,  1.42s/it, loss=0.226]\n",
            "Evaluating tests for Epoch: 1/10: 100%|██████████| 66/66 [01:05<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 1..f1: (0.8064405237682241, 0.9421279082080406), loss: (0.7354383390567457, 0.20756088710869802)\n",
            "Completed training Epoch: 1..recall: (0.8082845887549241, 0.9422434367541767), precision: (0.815179734088142, 0.9430749579213973)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 2/10: 100%|██████████| 262/262 [06:12<00:00,  1.42s/it, loss=0.12]\n",
            "Evaluating tests for Epoch: 2/10: 100%|██████████| 66/66 [01:04<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 2..f1: (0.9435688350336278, 0.9483890397095958), loss: (0.18579392459684316, 0.17063757940901048)\n",
            "Completed training Epoch: 2..recall: (0.9436552465082966, 0.9484486873508353), precision: (0.9436160798323323, 0.9487741604875984)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 3/10: 100%|██████████| 262/262 [06:06<00:00,  1.40s/it, loss=0.182]\n",
            "Evaluating tests for Epoch: 3/10: 100%|██████████| 66/66 [01:04<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 3..f1: (0.9765841108358932, 0.9549954402180706), loss: (0.09499181561769192, 0.15078174856942939)\n",
            "Completed training Epoch: 3..recall: (0.9766026023636146, 0.9551312649164678), precision: (0.9766467794628889, 0.9550627161257722)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 4/10: 100%|██████████| 262/262 [06:11<00:00,  1.42s/it, loss=0.081]\n",
            "Evaluating tests for Epoch: 4/10: 100%|██████████| 66/66 [01:04<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 4..f1: (0.9813639991921037, 0.9575280674294896), loss: (0.07080585839944885, 0.1591123098676855)\n",
            "Completed training Epoch: 4..recall: (0.9813775814730811, 0.9575178997613365), precision: (0.9813699678897972, 0.9578068276380304)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 5/10: 100%|██████████| 262/262 [06:10<00:00,  1.42s/it, loss=0.0989]\n",
            "Evaluating tests for Epoch: 5/10: 100%|██████████| 66/66 [01:04<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 5..f1: (0.9820826448122649, 0.9569668201738741), loss: (0.06554300073918154, 0.147832420626373)\n",
            "Completed training Epoch: 5..recall: (0.982093828339501, 0.9570405727923628), precision: (0.9820850112241912, 0.9570166861749981)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 6/10: 100%|██████████| 262/262 [06:13<00:00,  1.42s/it, loss=0.0499]\n",
            "Evaluating tests for Epoch: 6/10: 100%|██████████| 66/66 [01:04<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 6..f1: (0.9820814713600141, 0.9546095148646692), loss: (0.0680189898685474, 0.1578409607437524)\n",
            "Completed training Epoch: 6..recall: (0.982093828339501, 0.954653937947494), precision: (0.9820997704610379, 0.9551366725275537)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 7/10: 100%|██████████| 262/262 [06:12<00:00,  1.42s/it, loss=0.0116]\n",
            "Evaluating tests for Epoch: 7/10: 100%|██████████| 66/66 [01:06<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 7..f1: (0.9841081500238092, 0.9536703533279561), loss: (0.06497720083513275, 0.15529464956401198)\n",
            "Completed training Epoch: 7..recall: (0.9841231944610243, 0.9536992840095465), precision: (0.9841225915282118, 0.9540352777849579)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 8/10: 100%|██████████| 262/262 [06:10<00:00,  1.42s/it, loss=0.00849]\n",
            "Evaluating tests for Epoch: 8/10: 100%|██████████| 66/66 [01:04<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 8..f1: (0.9836365574996774, 0.9580560638023933), loss: (0.0650672594881581, 0.15174152650588163)\n",
            "Completed training Epoch: 8..recall: (0.9836456965500776, 0.9579952267303102), precision: (0.9836433002042193, 0.9583757232767411)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 9/10: 100%|██████████| 262/262 [06:09<00:00,  1.41s/it, loss=0.102]\n",
            "Evaluating tests for Epoch: 9/10: 100%|██████████| 66/66 [01:04<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 9..f1: (0.9848300770481642, 0.9527316915998815), loss: (0.06391019183779775, 0.16265693013415192)\n",
            "Completed training Epoch: 9..recall: (0.9848394413274442, 0.952744630071599), precision: (0.9848504506758248, 0.9529854897330488)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 10/10: 100%|██████████| 262/262 [06:11<00:00,  1.42s/it, loss=0.0622]\n",
            "Evaluating tests for Epoch: 10/10: 100%|██████████| 66/66 [01:04<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed training Epoch: 10..f1: (0.985185950888213, 0.950168494200134), loss: (0.06393815954713478, 0.163572223363162)\n",
            "Completed training Epoch: 10..recall: (0.9851975647606541, 0.9503579952267303), precision: (0.9851957383169929, 0.9504840315245299)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>test f1</td><td>▁▄▇██▆▆█▆▅</td></tr><tr><td>test loss</td><td>█▄▁▂▁▂▂▁▃▃</td></tr><tr><td>test precision</td><td>▁▄▆█▇▇▆█▆▄</td></tr><tr><td>test recall</td><td>▁▄▇██▇▆█▆▅</td></tr><tr><td>train f1</td><td>▁▆████████</td></tr><tr><td>train loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train precision</td><td>▁▆████████</td></tr><tr><td>train recall</td><td>▁▆████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>10</td></tr><tr><td>test f1</td><td>0.95017</td></tr><tr><td>test loss</td><td>0.16357</td></tr><tr><td>test precision</td><td>0.95048</td></tr><tr><td>test recall</td><td>0.95036</td></tr><tr><td>train f1</td><td>0.98519</td></tr><tr><td>train loss</td><td>0.06394</td></tr><tr><td>train precision</td><td>0.9852</td></tr><tr><td>train recall</td><td>0.9852</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">second run</strong> at: <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/goq7yrfs' target=\"_blank\">https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3/runs/goq7yrfs</a><br> View project at: <a href='https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3' target=\"_blank\">https://wandb.ai/mabidoye4125-app/Animal%20Classification%20With%20Fine%20Tuned%20EfficientNet-B3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250626_134644-goq7yrfs/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "softmax = nn.Softmax()\n",
        "\n",
        "\n",
        "def predict_animal() -> None:\n",
        "  new_image = Image.open(input('Enter image url: ')).convert('RGB')\n",
        "  new_image = transform(new_image).unsqueeze(0)\n",
        "  new_image = new_image.to(device)\n",
        "  preds = model(new_image)\n",
        "  preds = softmax(preds)\n",
        "  probability, prediction = torch.max(preds, 1)\n",
        "\n",
        "  print(f'This is an image of {animal_list[prediction.item()]} with probability of {probability.item()}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predict_animal()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN3xl6Yax8K7",
        "outputId": "e5e2db82-2aa3-451d-eb9a-777f2d0dc220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter image url: /content/some_image.jpeg\n",
            "This is an image of dog with probability of 0.9983893632888794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqcEa3a-ywW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}